{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec5.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvBiplHVJYV7"
      },
      "source": [
        "# info\n",
        "- by: LeeHaEun\n",
        "- start: 21.11.08 Mon\n",
        "- end: 21.11.15 Mon\n",
        "- review: 21.11.15 Mon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIc3h6b0Jc4-"
      },
      "source": [
        "# theme:CNN+ - dog&cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FUG38cOJ6i4"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7c5gbgtKmYj"
      },
      "source": [
        "1. 이미지의 크기가 다를 때\n",
        "2. 컬러이미지\n",
        "  - 컴퓨터는 3차원으로 인식\n",
        "  - RGB 3개 컬러채널 -> 너비가 3인 육면체\n",
        "  - how to 컨볼루션 with 컬러이미지\n",
        "    - 필터 자체가 3차원(3개의 2차원 필터)\n",
        "    - 3개의 컨볼루션을 진행한다는 것 외에 차이 없음\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVl93V7R1w4I"
      },
      "source": [
        "## Softmax & Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQY8DJ-O1vey"
      },
      "source": [
        "tf.keras.layers.Dense(2, activation='softmax')\n",
        "# ------------------------------------------ #\n",
        "tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "model.compile(optimizer='adam', \n",
        "              loss='binary_crossentropy', # not sparse_categorial_crossentropy\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-mWa0nK2cqR"
      },
      "source": [
        "## 데이터 과적합 방지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b0Kpjbv2gll"
      },
      "source": [
        "트레이닝세트 > 검사세트 <- 모델이 트레이닝 세트를 암기하기 때문\n",
        "\n",
        "**Validation set** \n",
        "- validation ross를 확인\n",
        "- 과적합 방지를 위해\n",
        "- 테스트 세트, 트레이닝 세트와 분리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofRWcyFt3Ob0"
      },
      "source": [
        "1. Image augumentation\n",
        "- 원본 이미지에 다양한 필터를 적용해서 -> 이미지 개수를 늘린다\n",
        "2. Dropout\n",
        "- 가중치의 편차가 큰 경우\n",
        "- 훈련 중 특정 뉴런을 종료\n",
        "- -> 다른 뉴런의 활동이 활발해진다\n",
        "- 몇개는 꺼지고 몇개는 안꺼지겠지만, 우리가 훈련을 많이 시키기 때문에 큰 문제 없다 (평균적으로 꺼지는 횟수 동일)\n",
        "\n",
        "\n",
        "3. Early Stopping\n",
        "- In this method, we track the loss on the validation set during the training phase and use it to determine when to stop training such that the model is accurate but not overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL5DDWKr2b8T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enRQB-s1M_Mf"
      },
      "source": [
        "# code_l05c01_dogs_vs_cats_**without**_augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUtN4y6vOmNk"
      },
      "source": [
        "## 기본 세팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maTBvzO0OqRg"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BrWpF6YPCuv"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator # 여기에서 데이터를 불러옵니다\n",
        "\n",
        "import os # 디렉토리에서 파일을 읽어오는 패키지\n",
        "import matplotlib.pyplot as plt # 그래프 그려주는 패키지\n",
        "import numpy as np # 매트릭스 타입을 위한...\n",
        "\n",
        "import logging # 에러 잡으려고 ...\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1KVS5BSOsuE"
      },
      "source": [
        "### data loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX3iHBK0Prxk"
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auUTOpyrPxrB"
      },
      "source": [
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "!find $zip_dir_base -type d -print"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKiOLEO_QNJS"
      },
      "source": [
        "# 디렉토리에 이름을 붙여줍니다 <- 편하게 접근하려고\n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train') # 트레이닝 세트\n",
        "validation_dir = os.path.join(base_dir, 'validation') # 유효성 검사 세트\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tr1rVm-QoDa"
      },
      "source": [
        "#### 불러온 데이터를 확인해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIpSEN4zQxz4"
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir)) # 트레이닝 세트의 고양이 사진 개수\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir)) # 트레이닝 세트의 강아지 사진 개수\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir)) # 유효성 검사 세트의 고양이 사진 개수\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir)) # 유효성 검사 세트의 강아지 사진 개수\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr # 트레이닝 세트의 전체 사진 개수\n",
        "total_val = num_cats_val + num_dogs_val # 유효성 검사 세트의 전체 사진 개수\n",
        "\n",
        "# 변수 다 저장해놨으니까, 실제로 한번 보자고 프린트해보는 단계 ... 별거 없다\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPAWaf9dRm_q"
      },
      "source": [
        "## 모델 파라미터를 설정해봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz_i4cTER_vH"
      },
      "source": [
        "BATCH_SIZE = 100  # Number of training examples to process before updating our models variables\n",
        "IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onJVy7a7OxLN"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zNmqg63zs2F"
      },
      "source": [
        "train_image_generator      = ImageDataGenerator(rescale=1./255)  # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255)  # Generator for our validation data\n",
        "\n",
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                           class_mode='binary')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                              class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00eVgdPy0AW1"
      },
      "source": [
        "1. Read images from the disk\n",
        "2. Decode contents of these images and convert it into proper grid format as per their RGB content\n",
        "3. Convert them into floating point tensors\n",
        "4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
        "\n",
        "Fortunately, all these tasks can be done using the class **tf.keras.preprocessing.image.ImageDataGenerator**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFoQTZS7RhMj"
      },
      "source": [
        "### 트레이닝 이미지를 시각화해볼까요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPGlvNhi0C-L"
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen) \n",
        "\n",
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plotImages(sample_training_images[:5])  # Plot images 0-4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9wkDTJq0OtE"
      },
      "source": [
        "The `next` function returns a batch from the dataset. One batch is a tuple of (*many images*, *many labels*). For right now, we're discarding the labels because we just want to look at the images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXmT9ad3R3lS"
      },
      "source": [
        "## creating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HK3mkpS0ham"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoT_KHFs0mvH"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok7lAoOz0_-z"
      },
      "source": [
        "Let's look at all the layers of our network using summary method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6vqYIpq0oYq"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIVZgbCq0qMe"
      },
      "source": [
        "## Traing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgvYDY7w0tPH"
      },
      "source": [
        "EPOCHS = 100\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bauNDeA80u1p"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.savefig('./foo.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXL70jEl4Vhh"
      },
      "source": [
        "# code_l05c02_dogs_vs_cats_**with**_augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQer1n0t4shp"
      },
      "source": [
        "##goal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz3DBOov4u9V"
      },
      "source": [
        "1. 데이터 파이프라인 구축\n",
        "2. 과적합 방지 Overfitting\n",
        "3. data augumentation & dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSlWk6fH5BQa"
      },
      "source": [
        "## examine & understand data _ 1번이랑 same"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7YvgwyJ5dYs"
      },
      "source": [
        "### import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIs9IRMF5do1"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkkjKhqe5l43"
      },
      "source": [
        "### 데이터 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y189UHt5lV5"
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2uXOEiM5xCF"
      },
      "source": [
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82e7tpQk5xgj"
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKYXO10I52hk"
      },
      "source": [
        "### 데이터 확인하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xNQsdyv56pz"
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfzbxb-357Vv"
      },
      "source": [
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p0YBiiG6I_C"
      },
      "source": [
        "## 모델 파라미터 설정 _ 1번이랑 same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdv2tBaA6PiA"
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "IMG_SHAPE  = 150 # Our training data consists of images with width of 150 pixels and height of 150 pixels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sosbQP0j6U25"
      },
      "source": [
        "## data augumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZuy7PmF6YZF"
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_giP5Ov6oFo"
      },
      "source": [
        "#### 1. 이미지  플립-horizontally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejxp2LiO6u9k"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, horizontal_flip=True)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE,IMG_SHAPE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqRxodYV6xDB"
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxyaUrsc6q5d"
      },
      "source": [
        "#### 2. 이미지 로테이션-45도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR3X-yln69YN"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, rotation_range=45)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE, IMG_SHAPE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CgvxKnA6-hN"
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1Db0slW7AUT"
      },
      "source": [
        "#### 3. 이미지 확대-50%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blFP003M7Fyy"
      },
      "source": [
        "image_gen = ImageDataGenerator(rescale=1./255, zoom_range=0.5)\n",
        "\n",
        "train_data_gen = image_gen.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_SHAPE, IMG_SHAPE))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9uk08cu7G2L"
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7Tw60nf7Hys"
      },
      "source": [
        "#### 4. 전부다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yRbPXBf7J1o"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_SHAPE,IMG_SHAPE),\n",
        "                                                     class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_3z6jp97LDe"
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBLmzaN37ZEQ"
      },
      "source": [
        "#### => validation data set 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vDSvUAc7jKJ"
      },
      "source": [
        "- 데이터 아규멘테이션을 거친 이미지는 보통 training 세트에만 적용된다\n",
        "- 따라서, 유효성 검사 이미지만 다시 보정하고 배치로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcVEQAXo7Y3j"
      },
      "source": [
        "image_gen_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "                                                 class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usBRZQlK5Phm"
      },
      "source": [
        "## Build model_1번이랑 큰 차이 없다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuREHaBL8CxI"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvePobYq8Dq0"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it8iCR8W8FFF"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cyut2Kw5SJu"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le846S2S8JrB"
      },
      "source": [
        "epochs=100\n",
        "history = model.fit_generator(\n",
        "    train_data_gen,\n",
        "    steps_per_epoch=int(np.ceil(total_train / float(BATCH_SIZE))),\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    validation_steps=int(np.ceil(total_val / float(BATCH_SIZE)))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVGHpwz18NBI"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}