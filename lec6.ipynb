{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec6.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mdy_AHb9F2W"
      },
      "source": [
        "# info\n",
        "- by: LeeHaEun\n",
        "- start: 21.11.15 Mon\n",
        "- end: 21.11.15 Mon\n",
        "- review: 21.11.15 Mon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsxzB6219OJQ"
      },
      "source": [
        "# theme:Trasfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59LVfWxJ9jQ7"
      },
      "source": [
        "- 대규모 세트에서 훈련된 신경망 -> 이전에 본 적 없는 데이터 세트에 지식을 적용할 수 있다\n",
        "- 최종 출력 레이어만 변경하면 된다 (아웃풋의 종류가 다르기 때문)\n",
        "- 그 외는 변경 불가 (freezing model)\n",
        "  - 사전 훈련된 모델의 변수 = 훈련 불가능\n",
        "  - 마지막 분류 계층의 변수만 훈련되도록\n",
        "- 훈련 시간 단축 가능!\n",
        "- 가중치는 무작위로 초기화 -> 초기 오류 많다, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P7zeZXr_GOs"
      },
      "source": [
        "## Mobilenet\n",
        "- 메모리와 계산 리소스가 제한된 모바일 장치에서 사용하기 좋다\n",
        "- imagenet을 이용해서 훈련되었다\n",
        "- 텐서플로우 허브에서 사전 훈련된 모델을 다운 가능\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiLIn6d0AAQZ"
      },
      "source": [
        "# code_l06c01_tensorflow_hub_and_transfer_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KYVbYxWAE94"
      },
      "source": [
        "1. Use a TensorFlow Hub model for prediction.\n",
        "2. Use a TensorFlow Hub model for Dogs vs. Cats dataset.\n",
        "3. Do simple transfer learning with TensorFlow Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1fUYL5XAKYf"
      },
      "source": [
        "## import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8LHDVm-AEb6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2qv5EZ69CXF"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow_hub as hub #허브에서 모델 다운로드\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH2TnkS-APVS"
      },
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEfTh2SpATXa"
      },
      "source": [
        "## part1: 텐서플로우 허브의 모바일넷 사용(for prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxkG2ATEAdLj"
      },
      "source": [
        "### classifier 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdtrubjxAb9x"
      },
      "source": [
        "CLASSIFIER_URL =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/2\"\n",
        "IMAGE_RES = 224\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    hub.KerasLayer(CLASSIFIER_URL, input_shape=(IMAGE_RES, IMAGE_RES, 3))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVjApLgoAnx_"
      },
      "source": [
        "### 1개의 이미지로만 돌려봅시다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc8aHJmNArbL"
      },
      "source": [
        "# 이미지 다운로드\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "\n",
        "grace_hopper = tf.keras.utils.get_file('image.jpg','https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg')\n",
        "grace_hopper = Image.open(grace_hopper).resize((IMAGE_RES, IMAGE_RES))\n",
        "grace_hopper "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFtoIQ9pAuld"
      },
      "source": [
        "# 픽셀 값이 0-1 사이에 있도록 정규화\n",
        "grace_hopper = np.array(grace_hopper)/255.0\n",
        "grace_hopper.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1VxbqlcA7u_"
      },
      "source": [
        "# 트렌스퍼 한 모델에 러닝\n",
        "result = model.predict(grace_hopper[np.newaxis, ...])\n",
        "result.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrugaDpiA_uR"
      },
      "source": [
        "# 예측값\n",
        "predicted_class = np.argmax(result[0], axis=-1)\n",
        "predicted_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n98MKF1BWLT"
      },
      "source": [
        "# 예측값의 라벨이 뭔지?\n",
        "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')\n",
        "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
        "\n",
        "plt.imshow(grace_hopper)\n",
        "plt.axis('off')\n",
        "predicted_class_name = imagenet_labels[predicted_class]\n",
        "_ = plt.title(\"Prediction: \" + predicted_class_name.title())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUlEob4dBTgL"
      },
      "source": [
        "## part2: 텐서플로우 허브 모델을 강아지-고양이 데이터에 적용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNBpJGcB49o"
      },
      "source": [
        "### dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH5INc_aB8MA"
      },
      "source": [
        "# 이미지 저장\n",
        "(train_examples, validation_examples), info = tfds.load(\n",
        "    'cats_vs_dogs', \n",
        "    with_info=True, \n",
        "    as_supervised=True, \n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        ")\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7Yg9ziWCHRW"
      },
      "source": [
        "# 사이즈가 달라요 - 확인해봅시다\n",
        "for i, example_image in enumerate(train_examples.take(3)):\n",
        "  print(\"Image {} shape: {}\".format(i+1, example_image[0].shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYa8xnLvCM8p"
      },
      "source": [
        "# 리사이즈 해볼까요 - 모바일넷의 인풋은 (224,224)로 고정\n",
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0\n",
        "  return image, label\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_batches      = train_examples.shuffle(num_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OV5w1w9CiNL"
      },
      "source": [
        "The .repeat() and steps_per_epoch here is not required, but saves ~15s per epoch, since the shuffle-buffer only has to cold-start once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp0PdjaLC_yx"
      },
      "source": [
        "### run!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3n92XmQCj_Q"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_batches.take(1)))\n",
        "image_batch = image_batch.numpy()\n",
        "label_batch = label_batch.numpy()\n",
        "\n",
        "result_batch = model.predict(image_batch)\n",
        "\n",
        "predicted_class_names = imagenet_labels[np.argmax(result_batch, axis=-1)]\n",
        "predicted_class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2SFmrCTCzTF"
      },
      "source": [
        "# 확인해봅시다\n",
        "plt.figure(figsize=(10,9))\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.subplots_adjust(hspace = 0.3)\n",
        "  plt.imshow(image_batch[n])\n",
        "  plt.title(predicted_class_names[n])\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"ImageNet predictions\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54uk9bwnDCyJ"
      },
      "source": [
        "## part3: 간단한 트랜스퍼 러닝을 해봅시다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zig19pjID2IH"
      },
      "source": [
        "### feature_extacter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zGxsbrKDf3V"
      },
      "source": [
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "                                   input_shape=(IMAGE_RES, IMAGE_RES,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajWcxeUoDgPc"
      },
      "source": [
        "feature_batch = feature_extractor(image_batch)\n",
        "print(feature_batch.shape)\n",
        "#-> 32, 1280\n",
        "# 32:이미지 개수\n",
        "# 1280: 뉴런의 개수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMSHEsK7Dq5k"
      },
      "source": [
        "# 추출 레이어의 변수 동결 -> classifier layer 만 변경\n",
        "feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2edxGxxD6i6"
      },
      "source": [
        "### classifier layer 수정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MNvyZ1VD-9W"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_extractor,\n",
        "  layers.Dense(2) #output 2개로 변경\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4DCYmjRELZm"
      },
      "source": [
        "### 모델 학습시키기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLYvjLx0EK1m"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 6\n",
        "history = model.fit(train_batches,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches)\n",
        "\n",
        "#-> 검증 정확도 97%\n",
        "# 모바일넷은 전문가에 의해 신중하게 설계되고, 대규모 데이터세트(이미지넷)에 의해 교육되었기 때문"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0q-XqOdEfZJ"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(EPOCHS)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euQvOs7vEo51"
      },
      "source": [
        "validation performance > training performance\n",
        "1. v는 epoch말기에 측정, t는 전체의 평균 값\n",
        "2. 이미 개와 고양이 이미지에 대해 교육받은 모바일넷의 많은 부분을 재사용하고 있기 때문\n",
        "  - t에 대해서는 image augumentation 하지만, v는 안한다.\n",
        "  - = t가 더 어려울 수 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeiMng4FN8A"
      },
      "source": [
        "### Check the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_SOVs2QE8l7"
      },
      "source": [
        "class_names = np.array(info.features['label'].names)\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0rc_yX9FSCn"
      },
      "source": [
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
        "predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_class_names = class_names[predicted_ids]\n",
        "predicted_class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ESoVdbFU0J"
      },
      "source": [
        "print(\"Labels: \", label_batch)\n",
        "print(\"Predicted labels: \", predicted_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1a51HbZFVO-"
      },
      "source": [
        "plt.figure(figsize=(10,9))\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.subplots_adjust(hspace = 0.3)\n",
        "  plt.imshow(image_batch[n])\n",
        "  color = \"blue\" if predicted_ids[n] == label_batch[n] else \"red\"\n",
        "  plt.title(predicted_class_names[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}