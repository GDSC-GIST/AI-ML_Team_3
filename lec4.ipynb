{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lec4.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNWywP1x61qwhNRG0m6bJYt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4rVmvB-tcu65"},"source":["# info\n","- by: LeeHaEun\n","- start: 21.11.08 Mon\n","- end: 21.11.08 Mon\n","- review: 21.11.08 Mon"]},{"cell_type":"markdown","metadata":{"id":"eySJo6i1cw1n"},"source":["# theme: CNN"]},{"cell_type":"markdown","metadata":{"id":"9hH5PfxNc8tC"},"source":["## 모델의 성능 올리는 방법\n","=> **CNN** 사용(convolution neural network)\n","1. convolution\n","  - goal: 여러가지 필터를 통해 얻어낸 맵 중, 해당 이미지의 특징을 가장 잘 나타내는 것 find -> 이미지의 특징 파악\n","  - kernal 이라는 필터를 적용\n","    - **stride**: 필터를 적용하는 간격\n","  - 가장자리?\n","    - 없는 것으로 치거나\n","    - zero padding 사용: 가장자기에 0인 셀이 있다고 가정\n","2. maxpooling\n","  - 영역을 요약해서 입력 이미지의 크기를 줄이는 과정 = **downsampling**\n","  - 특정 grid 안의 값 중 가장 큰 값을 선택\n","  - 이렇게 하면 사이즈 절반 됨\n","  => 기준으로 잡는 그리드의 크기에 따라 달라진다\n"]},{"cell_type":"markdown","metadata":{"id":"Eo-fvjOXhL9q"},"source":["## terms\n","- **Convolution layer**\n","  - dense layer랑 유사\n","  - karas의 `Conv2D` 레이어 타입으로 사용 가능\n","  - weight, biases, kernal 포함\n","  - 필터 매트릭스 내부의 값 = 올바른 출력을 내기 위해 조정되는 변수\n","  - => 입력받은 이미지에 대한 특징 추출\n","- **CNN**: 컨볼루션 레이어를 적어도 한 개 이상 가지고 있는 네트워크\n"]},{"cell_type":"markdown","metadata":{"id":"ZZmISCsAc0K5"},"source":["# code_l04c01_image_classification_with_cnns"]},{"cell_type":"markdown","metadata":{"id":"FHkpfV9cc6oV"},"source":["## 기본 세팅"]},{"cell_type":"code","metadata":{"id":"RswL3J5dXvcH"},"source":["import tensorflow as tf\n","\n","# Import TensorFlow Datasets\n","import tensorflow_datasets as tfds\n","tfds.disable_progress_bar()\n","\n","# Helper libraries\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import logging\n","logger = tf.get_logger()\n","logger.setLevel(logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zItdioy7kgNg"},"source":["### import MNIST data set"]},{"cell_type":"code","metadata":{"id":"rNTpFFzpkwQ6"},"source":["dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n","train_dataset, test_dataset = dataset['train'], dataset['test']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pKkAbKsCk22r"},"source":["class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bxkvilCslKJR"},"source":["-> label 이름이 dataset안에 없으니까 저장해두기"]},{"cell_type":"markdown","metadata":{"id":"IxPbgjyvlSEn"},"source":["### 불러온 데이터를 확인해볼까용"]},{"cell_type":"code","metadata":{"id":"ZBHLeNLolVSe"},"source":["num_train_examples = metadata.splits['train'].num_examples\n","num_test_examples = metadata.splits['test'].num_examples\n","print(\"Number of training examples: {}\".format(num_train_examples))\n","print(\"Number of test examples:     {}\".format(num_test_examples))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rpyiAY__lYSM"},"source":["트레이닝 세트 60000개, 테스트 세트 10000개"]},{"cell_type":"markdown","metadata":{"id":"VkS4prfMldrz"},"source":["## 데이터 전처리 (lec 3이랑 same)"]},{"cell_type":"code","metadata":{"id":"_CqFeCCqlgm0"},"source":["def normalize(images, labels):\n","  images = tf.cast(images, tf.float32) #이미지를 float으로 캐스팅\n","  images /= 255 #255로 나누기\n","  return images, labels\n","\n","# dataset를 normalize해서 덮어씌우기\n","train_dataset =  train_dataset.map(normalize)\n","test_dataset  =  test_dataset.map(normalize)\n","\n","# 처음 dataset 사용할 때에는 disk에 로드된다 -> caching하면 memory로 불러온다 -> faster!\n","train_dataset =  train_dataset.cache()\n","test_dataset  =  test_dataset.cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hgdcLA8tl3QZ"},"source":["- **tf.cast** = 새로운 형태로 cast\n","- **map**: 함수를 데이터에 적용\n","  - → map(함수, 데이터)\n","  - → 데이터.map(함수)\n","- **cache()**는 그냥 데이터 저장소"]},{"cell_type":"markdown","metadata":{"id":"_rIB4btTlj8O"},"source":["### 전처리 된 데이터를 살펴볼까용"]},{"cell_type":"code","metadata":{"id":"2Km2ljZElml7"},"source":["# Take a single image, and remove the color dimension by reshaping\n","for image, label in test_dataset.take(1): #testset에서 1개만 불러오기->image,label\n","  break\n","image = image.numpy().reshape((28,28)) #image를 넘파이 파입으로 저장\n","\n","# Plot the image - voila a piece of fashion clothing\n","plt.figure()\n","plt.imshow(image, cmap=plt.cm.binary)\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tp-OerZimFN5"},"source":["take(): 해당 배치(배치작업은, 데이터를 실시간으로 처리하는게 아니라, 일괄적으로 모아서 처리하는 작업을 의미한다.)를 몇 번 불러올지 정한다\n","\n","\n","cmap은 색깔 차트\n","\n","plt는 위에서 matplotlib으로 선언했음"]},{"cell_type":"code","metadata":{"id":"1nU_-T6HmIG3"},"source":["plt.figure(figsize=(10,10))\n","i = 0\n","for (image, label) in test_dataset.take(25):\n","    image = image.numpy().reshape((28,28))\n","    plt.subplot(5,5,i+1)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.grid(False)\n","    plt.imshow(image, cmap=plt.cm.binary)\n","    plt.xlabel(class_names[label])\n","    i += 1\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rt4nN9fxmKId"},"source":["matplotlib.pyplot 모듈의 subplot(rows, cols, index) 함수는 여러 개의 그래프를 하나의 그림에 나타내도록 합니다.\n"]},{"cell_type":"markdown","metadata":{"id":"sRSkqWCxmZCH"},"source":["## 모델 만들기(**layer setting에서 차이가 있음!**)"]},{"cell_type":"markdown","metadata":{"id":"t4-PqwGWm-FR"},"source":["### 레이어 세팅"]},{"cell_type":"code","metadata":{"id":"4QURCv3Cm_mU"},"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n","                           input_shape=(28, 28, 1)), # 입력 이미지에 적용되는 필터: 원래 사이즈 유지 32개의 컨볼루션 이미지 생성\n","    tf.keras.layers.MaxPooling2D((2, 2), strides=2), #stride 2인 풀링 -> 32개 출력의 크기 줄이기\n","    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu), # 입력 이미지, 64개 출력\n","    tf.keras.layers.MaxPooling2D((2, 2), strides=2), # 마찬가지로 64개 출력의 크기 줄이기\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(128, activation=tf.nn.relu), #128개 노드로부터 입력받아\n","    tf.keras.layers.Dense(10, activation=tf.nn.softmax) #output 노드=10개\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t5ruvNIdnDCQ"},"source":["### 모델 컴파일(로스펑션, 옵티마이저, 메트릭스)"]},{"cell_type":"code","metadata":{"id":"LB4maPB2nE6X"},"source":["model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZqXe6XmLmbVj"},"source":["## 모델 학습시키기(lec3이랑 same)(**정확도는 더 높다! 0.97**)"]},{"cell_type":"code","metadata":{"id":"grb-qHKTom0A"},"source":["BATCH_SIZE = 32\n","train_dataset = train_dataset.cache().repeat().shuffle(num_train_examples).batch(BATCH_SIZE)\n","test_dataset = test_dataset.cache().batch(BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o78pq_izoom3"},"source":["model.fit(train_dataset, epochs=10, steps_per_epoch=math.ceil(num_train_examples/BATCH_SIZE))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5QnnyCwVq376"},"source":["As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.97 (or 97%) on the training data.\n","\n","=> lecc3보다 정확도가 높다!"]},{"cell_type":"markdown","metadata":{"id":"cpj3BdbUmdHO"},"source":["## 모델 정확도 판단(lec3이랑 same)"]},{"cell_type":"code","metadata":{"id":"UzGKAg0MorHF"},"source":["test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n","print('Accuracy on test dataset:', test_accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jfEpX_kvouPJ"},"source":["## 예측하고 돌려봅시다(lec3이랑 same)"]},{"cell_type":"code","metadata":{"id":"VXGjNfCQoxsP"},"source":["for test_images, test_labels in test_dataset.take(1):\n","  test_images = test_images.numpy()\n","  test_labels = test_labels.numpy()\n","  predictions = model.predict(test_images)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eWlvdPUo1pC"},"source":["predictions.shape #(32,10)\n","predictions[0] #0번에 관한 예측 확률 제시\n","np.argmax(predictions[0]) #위의 확률중에 제일 큰거 return\n","test_labels[0] #실제로 4인것을 확인할 수 있다"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jodpx1Nfo60V"},"source":["def plot_image(i, predictions_array, true_labels, images): #이미지와 주석\n","  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  \n","  plt.imshow(img[...,0], cmap=plt.cm.binary)\n","\n","  predicted_label = np.argmax(predictions_array)\n","  if predicted_label == true_label:\n","    color = 'blue'\n","  else:\n","    color = 'red'\n","  \n","  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n","                                100*np.max(predictions_array),\n","                                class_names[true_label]),\n","                                color=color)\n","\n","def plot_value_array(i, predictions_array, true_label): ##막대그래프\n","  predictions_array, true_label = predictions_array[i], true_label[i]\n","  plt.grid(False)\n","  plt.xticks([])\n","  plt.yticks([])\n","  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n","  plt.ylim([0, 1])\n","  predicted_label = np.argmax(predictions_array)\n","  \n","  thisplot[predicted_label].set_color('red')\n","  thisplot[true_label].set_color('blue')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kziTFG8do8Az"},"source":["# 예시 하나만 띄워봅시다\n","i = 0\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(i, predictions, test_labels, test_images)\n","plt.subplot(1,2,2)\n","plot_value_array(i, predictions, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38QH8n1Po87s"},"source":["# 예시 하나만 띄워봅시다\n","i = 12\n","plt.figure(figsize=(6,3))\n","plt.subplot(1,2,1)\n","plot_image(i, predictions, test_labels, test_images)\n","plt.subplot(1,2,2)\n","plot_value_array(i, predictions, test_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6OkQ4Zxo90V"},"source":["# 예시 여러개 한번에 띄워봅시다\n","# Plot the first X test images, their predicted label, and the true label\n","# Color correct predictions in blue, incorrect predictions in red\n","num_rows = 5\n","num_cols = 3\n","num_images = num_rows*num_cols\n","plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n","for i in range(num_images):\n","  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n","  plot_image(i, predictions, test_labels, test_images)\n","  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n","  plot_value_array(i, predictions, test_labels)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y7O-HuWyo_Au"},"source":["# Grab an image from the test dataset\n","img = test_images[0]\n","\n","print(img.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iQ6qqr2qpEL3"},"source":["# Add the image to a batch where it's the only member.\n","img = np.array([img])\n","\n","print(img.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iR5ANC-ppGE6"},"source":["predictions_single = model.predict(img)\n","print(predictions_single)\n","\n","plot_value_array(0, predictions_single, test_labels)\n","_ = plt.xticks(range(10), class_names, rotation=45)\n","\n","np.argmax(predictions_single[0])"],"execution_count":null,"outputs":[]}]}